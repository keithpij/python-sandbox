{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "Introducing the BCE Loss Function<br>\n",
    "The BCE Loss Function with a Scalar<br>\n",
    "Visualizing the BCE Loss Function<br>\n",
    "The BCE Loss Function with a Vector<br>\n",
    "Breaking the BCE Loss Function<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x: np.ndarray, y1: np.ndarray, y2: np.ndarray=None) -> None:\n",
    "    ax = plt.subplots()[1]\n",
    "    ax.set_xlim(x.min(), x.max())\n",
    "    ax.set_ylim(y1.min(), y1.max())\n",
    "    plt.scatter(x, y1, color='blue')\n",
    "    if not y2 is None:\n",
    "        ax.scatter(x, y2, color='red')\n",
    "    plt.grid(True)\n",
    "    plt.axhline(color='black')\n",
    "    plt.axvline(color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The log of some number x is the exponent by which some other number known as the base must be raised to get the number x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = 100\n",
    "base = 10\n",
    "print(math.log(x, base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euler's number: 2.718281828459045\n",
      "4.605170185988092\n",
      "4.605170185988092\n"
     ]
    }
   ],
   "source": [
    "print(\"Euler's number:\", math.e)\n",
    "print(math.log(x))\n",
    "print(math.log(x, math.e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6052)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(100)\n",
    "print(torch.log(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the BCE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample implementation for descriptive purposes.\n",
    "def my_bce_loss(prediction: Tensor, target: Tensor) -> Tensor:\n",
    "    a = target * torch.log(prediction)\n",
    "    b = (1 - target) * (torch.log(1 - prediction))\n",
    "    return -(a+b).mean()\n",
    "\n",
    "prediction = torch.tensor(.01, dtype=torch.float32)\n",
    "target = torch.tensor(1, dtype=torch.float32)\n",
    "print(prediction)\n",
    "print(target)\n",
    "\n",
    "# My loss function\n",
    "loss = my_bce_loss(prediction, target)\n",
    "print(loss)\n",
    "\n",
    "# This is the loss class that Pytorch provides.\n",
    "bce_loss = nn.BCELoss()\n",
    "loss = bce_loss(prediction, target)\n",
    "print(loss)\n",
    "\n",
    "# This is the loss function Pytorch provides.\n",
    "loss = F.binary_cross_entropy(prediction, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the BCE Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use float16 you get a weird error from the loss function because the BCE function has\n",
    "# not implemented the float16 data type.\n",
    "#predictions = [torch.tensor(p/100, dtype=torch.float32) for p in range(1, 101)]\n",
    "#target = torch.tensor(1, dtype=torch.float32)\n",
    "\n",
    "predictions = [torch.tensor(p/100, dtype=torch.float32) for p in range(0, 100)]\n",
    "target = torch.tensor(0, dtype=torch.float32)\n",
    "\n",
    "weight = torch.tensor(1, dtype=torch.int32)\n",
    "\n",
    "display_predictions = [p.item() for p in predictions]\n",
    "print(display_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [F.binary_cross_entropy(p, target, weight) for p in predictions]\n",
    "\n",
    "display_losses = [l.item() for l in losses]\n",
    "print(display_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(np.array(predictions), np.array(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
