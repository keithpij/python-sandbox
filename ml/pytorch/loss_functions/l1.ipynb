{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "Introducing the L1 Loss Function<br>\n",
    "The L1 Loss Function with a Scalar<br>\n",
    "Visualizing Loss Functions<br>\n",
    "The L1 Loss Function with a Vector<br>\n",
    "A Bad Loss Function<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the L1 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3., dtype=torch.float16)\n",
      "tensor(3., dtype=torch.float16)\n",
      "tensor(3., dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "# Sample implementation for descriptive purposes.\n",
    "def my_l1_loss(prediction: Tensor, target: Tensor) -> Tensor:\n",
    "    return (prediction-target).abs().mean()\n",
    "\n",
    "prediction = torch.tensor(5, dtype=torch.float16)\n",
    "target = torch.tensor(2, dtype=torch.float16)\n",
    "\n",
    "# My loss function\n",
    "loss = my_l1_loss(prediction, target)\n",
    "print(loss)\n",
    "\n",
    "# This is the loss class that Pytorch provides.\n",
    "l1_loss = nn.L1Loss()\n",
    "loss = l1_loss(prediction, target)\n",
    "print(loss)\n",
    "\n",
    "# This is the loss function Pytorch provides.\n",
    "loss = F.l1_loss(prediction, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The L1 Loss Function with a Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the prediction to be smaller than the label and see\n",
    "# what happens to the gradient.\n",
    "#prediction = torch.tensor(10, dtype=torch.float64)\n",
    "prediction = torch.tensor(10, dtype=torch.float64)\n",
    "prediction.requires_grad_()\n",
    "label = torch.tensor(2, dtype=torch.float64)\n",
    "\n",
    "loss = F.l1_loss(prediction, label) \n",
    "loss.backward()\n",
    "\n",
    "print('loss Dimensions:', loss.ndim)\n",
    "print('loss Shape:', loss.shape)\n",
    "print(loss)\n",
    "\n",
    "print('\\nGradient Dimensions:', prediction.grad.ndim)\n",
    "print('Gradient Shape:', prediction.grad.shape)\n",
    "print(prediction.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The L1 Loss Function with a Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.tensor([-2, 5, 13], dtype=torch.float64)\n",
    "prediction.requires_grad_()\n",
    "label = torch.tensor([2, 5, 9], dtype=torch.float64)\n",
    "\n",
    "loss = F.l1_loss(prediction, label) \n",
    "loss.backward()\n",
    "\n",
    "print('loss Dimensions:', loss.ndim)\n",
    "print('loss Shape:', loss.shape)\n",
    "print(loss)\n",
    "\n",
    "print('\\nGradient Dimensions:', prediction.grad.ndim)\n",
    "print('Gradient Shape:', prediction.grad.shape)\n",
    "print(prediction.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Bad Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_bad_loss(guess: Tensor, answer: Tensor) -> Tensor:\n",
    "    return (guess-answer).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = torch.tensor([-2, 5, 13], dtype=torch.float64)\n",
    "prediction.requires_grad_()\n",
    "label = torch.tensor([2, 5, 9], dtype=torch.float64)\n",
    "\n",
    "loss = my_bad_loss(prediction, label) \n",
    "loss.backward()\n",
    "\n",
    "print('loss Dimensions:', loss.ndim)\n",
    "print('loss Shape:', loss.shape)\n",
    "print(loss)\n",
    "\n",
    "print('\\nGradient Dimensions:', prediction.grad.ndim)\n",
    "print('Gradient Shape:', prediction.grad.shape)\n",
    "print(prediction.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Guessing Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess = torch.tensor([50, 50, 50], dtype=torch.float64)\n",
    "guess.requires_grad_()\n",
    "answer = torch.tensor([2, 77, 91], dtype=torch.float64)\n",
    "loss = mse(guess, answer)\n",
    "\n",
    "loss.backward()\n",
    "lr = 1e-1   # This is 0.1\n",
    "step = lr * guess.grad.data\n",
    "\n",
    "print('loss Dimensions:', loss.ndim)\n",
    "print('loss Shape:', loss.shape)\n",
    "print(loss)\n",
    "\n",
    "print('\\nGradient Dimensions:', guess.grad.ndim)\n",
    "print('Gradient Shape:', guess.grad.shape)\n",
    "print(guess.grad)\n",
    "\n",
    "print('\\nStep Dimensions:', step.ndim)\n",
    "print('Step Shape:', step.shape)\n",
    "print(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attempts = 20\n",
    "answer = torch.tensor([2, 77, 91], dtype=torch.float64)\n",
    "guess = torch.tensor([50, 50, 50], dtype=torch.float64)\n",
    "guess.requires_grad_()\n",
    "\n",
    "for attempt in range(attempts):\n",
    "    loss = mse(guess, answer)\n",
    "\n",
    "    loss.backward()\n",
    "    lr = 10\n",
    "    step = lr * guess.grad.data\n",
    "    print(attempt+1, guess.data, loss.data, guess.grad.data, step.data)\n",
    "    guess.data -= step\n",
    "    guess.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the L1 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [torch.tensor(p, dtype=torch.float16) for p in range(-8, 13)]\n",
    "target = torch.tensor(2, dtype=torch.float16)\n",
    "\n",
    "display_predictions = [p.item() for p in predictions]\n",
    "print(display_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [F.l1_loss(p, target) for p in predictions]\n",
    "#losses = [my_bad_loss(p, target) for p in predictions]\n",
    "\n",
    "# We cannot do this because we want a loss for every value in x. \n",
    "# We do not want a single scalar value.\n",
    "#losses = F.f1_loss(predictions, target)\n",
    "\n",
    "display_losses = [l.item() for l in losses]\n",
    "print(display_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x: np.ndarray, y1: np.ndarray, y2: np.ndarray=None) -> None:\n",
    "    ax = plt.subplots()[1]\n",
    "    ax.set_xlim(x.min()-5, x.max()+5)\n",
    "    ax.set_ylim(y1.min()-5, y1.max()+5)\n",
    "    plt.scatter(x, y1, color='blue')\n",
    "    if not y2 is None:\n",
    "        ax.scatter(x, y2, color='red')\n",
    "    plt.grid(True)\n",
    "    plt.axhline(color='black')\n",
    "    plt.axvline(color='black')\n",
    "\n",
    "\n",
    "plot_data(np.array(predictions), np.array(losses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
