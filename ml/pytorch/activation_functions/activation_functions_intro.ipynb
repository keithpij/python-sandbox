{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "A Model Without an Activation Function<br>\n",
    "&emsp;Linear Example<br>\n",
    "&emsp;Quadratic Example<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Model without an Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_linear_data(weight:float, bias: float) -> tuple[List[float], List[float]]:\n",
    "    X = [float(x) for x in range(-10, 10)]\n",
    "    y = [weight*x+bias for x in X]\n",
    "    X, y = np.array(X, dtype=np.float32), np.array(y, np.float32)\n",
    "    X = np.reshape(X, (len(X), 1))\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    return X, y\n",
    "\n",
    "# We need to reshape X and y so that each row is a single feature/label.\n",
    "# This is needed for training.\n",
    "X_train, y_train = create_linear_data(5, 9)\n",
    "\n",
    "print('X_train Dimenstions:',X_train.ndim)\n",
    "print('X_train Shape:', X_train.shape)\n",
    "print(X_train[:2])\n",
    "\n",
    "print('y_train Dimenstions:',y_train.ndim)\n",
    "print('y_train Shape:', y_train.shape)\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x: np.ndarray, y1: np.ndarray, y2: np.ndarray=None) -> None:\n",
    "    ax = plt.subplots()[1]\n",
    "    ax.set_xlim(x.min()-5, x.max()+5)\n",
    "    ax.set_ylim(y1.min()-5, y1.max()+5)\n",
    "    plt.scatter(x, y1, color='blue')\n",
    "    if not y2 is None:\n",
    "        ax.scatter(x, y2, color='red')\n",
    "    plt.grid(True)\n",
    "    plt.axhline(color='black')\n",
    "    plt.axvline(color='black')\n",
    "\n",
    "plot_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(1, 1, bias=True)\n",
    "\n",
    "    def forward(self, input, log=False):\n",
    "        l1 = self.linear1(input)\n",
    "        if log:\n",
    "            print('\\nLinear 1:', l1, l1.shape)\n",
    "        return l1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Model with a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()\n",
    "X = torch.tensor([1], dtype=torch.float32)\n",
    "prediction = model(X, log=True)\n",
    "print(X)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# When you have a large number of iterations over a small training set you are basically\n",
    "# memorizing your training set.\n",
    "\n",
    "EPOCHS = 100\n",
    "LR = 0.001\n",
    "\n",
    "def train_model(model: nn.Module, X_train, y_train) -> tuple[nn.Module, List]:\n",
    "    torch.manual_seed(42)\n",
    "    losses = []\n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=LR)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        for X, y in zip(X_train, y_train):\n",
    "\n",
    "            # Wrap in tensors\n",
    "            X_tensor = torch.from_numpy(X)\n",
    "            y_tensor = torch.from_numpy(y)\n",
    "            \n",
    "            # Pytorch accumulates gradients so before passing in a new\n",
    "            # context (features) you need to zero out the gradients from the \n",
    "            # previous context.\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass - this will get log probabilities for every word \n",
    "            # in our vocabulary which is now represented as embeddings.\n",
    "            prediction = model(X_tensor)\n",
    "\n",
    "            # Compute the loss.\n",
    "            # target has to be a list for some reason.\n",
    "            loss = loss_function(prediction, y_tensor)\n",
    "\n",
    "            # Backward pass to update the gradients.\n",
    "            loss.backward()\n",
    "\n",
    "            # Optimize the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Get the loss for this context.\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "        # Save the total loss for this epoch.\n",
    "        losses.append(total_loss)\n",
    "\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(model: nn.Module, losses: list) -> None:\n",
    "    # Print the losses of every 10th epoch.\n",
    "    for epoch in range(0, EPOCHS, 10):\n",
    "        print(epoch, ':', losses[epoch])\n",
    "    # This will print the very last epoch so we can see the\n",
    "    # final loss value.\n",
    "    print(EPOCHS-1, ':', losses[EPOCHS-1])\n",
    "\n",
    "    for name, parameter in model.named_parameters():\n",
    "        print(name, parameter.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LinearRegressionModel()\n",
    "model, losses = train_model(model, X_train, y_train)\n",
    "\n",
    "# The loss should decrease with every iteration (epoch) over the training data.\n",
    "print_results(model, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model(torch.from_numpy(X)).detach().item() for X in X_train]\n",
    "\n",
    "plot_data(np.array(X_train), np.array(y_train), np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quadratic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quadratic_data(a:float, b: float, c:float) -> tuple[List[float], List[float]]:\n",
    "    X = [float(x) for x in range(-10, 11)]\n",
    "    y = [a*(x**2)+(b*x)+c for x in X]\n",
    "    X, y = np.array(X, dtype=np.float32), np.array(y, np.float32)\n",
    "    X = np.reshape(X, (len(X), 1))\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = create_quadratic_data(5, 2, 3)\n",
    "\n",
    "print('X_train Dimenstions:',X_train.ndim)\n",
    "print('X_train Shape:', X_train.shape)\n",
    "print(X_train[:2])\n",
    "\n",
    "print('y_train Dimenstions:',y_train.ndim)\n",
    "print('y_train Shape:', y_train.shape)\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(QuadraticRegressionModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(1, 6, bias=True)\n",
    "        self.linear2 = nn.Linear(6, 6, bias=True)\n",
    "        self.linear3 = nn.Linear(6, 1, bias=True)\n",
    "\n",
    "    def forward(self, input, log=False):\n",
    "        out = self.linear1(input)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.5)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([-0.1201], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticRegressionModel()\n",
    "X = torch.tensor([1], dtype=torch.float32)\n",
    "prediction = model(X, log=True)\n",
    "print(X)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 17505.414018914104\n",
      "10 : 15787.651941537857\n",
      "20 : 18625.464256048203\n",
      "30 : 16565.235090255737\n",
      "40 : 15929.981842041016\n",
      "50 : 16262.23739349842\n",
      "60 : 17962.81825309992\n",
      "70 : 15117.124224185944\n",
      "80 : 16236.015011787415\n",
      "90 : 17911.38174057007\n",
      "99 : 16902.339913129807\n",
      "linear1.weight tensor([[ 1.6168e+04],\n",
      "        [ 3.6443e-02],\n",
      "        [ 1.8569e+01],\n",
      "        [ 2.7119e-02],\n",
      "        [-4.3282e+00],\n",
      "        [ 2.0051e+00]])\n",
      "linear1.bias tensor([-3.2348e+03, -6.3758e-01, -3.7179e+00,  1.6593e+00,  1.4655e+00,\n",
      "        -8.7136e-01])\n",
      "linear2.weight tensor([[-5.9438e-01, -6.4062e-02, -3.2608e-01, -6.3070e-01, -7.1281e-01,\n",
      "         -3.8512e-01],\n",
      "        [-2.6820e-01, -2.7831e-01, -1.7763e-01, -2.6404e-01, -2.5910e-01,\n",
      "         -1.4227e-01],\n",
      "        [-1.0006e+00, -2.8975e-01, -8.4744e-01, -1.4949e+00, -1.5695e+00,\n",
      "         -9.4669e-01],\n",
      "        [-8.8702e+00,  2.7753e-01, -3.3916e+00, -1.6955e-01, -3.2623e+00,\n",
      "         -1.0005e+01],\n",
      "        [-1.4473e-01, -3.9502e-01, -2.3379e-01, -6.8162e-02, -6.3490e-02,\n",
      "         -2.9634e-01],\n",
      "        [-1.6518e+04, -2.7887e-01, -2.5711e+01, -2.2481e-01, -3.5730e-01,\n",
      "         -1.8614e+00]])\n",
      "linear2.bias tensor([-1.5588e-02,  3.4307e-01,  2.2531e+00, -1.6909e+00, -2.7590e-01,\n",
      "        -6.5838e+02])\n",
      "linear3.weight tensor([[ 1.1478e+00, -4.4100e-01, -2.8433e+00, -1.3770e+01, -7.5674e-02,\n",
      "         -4.7671e+02]])\n",
      "linear3.bias tensor([7.8707])\n"
     ]
    }
   ],
   "source": [
    "model = QuadraticRegressionModel()\n",
    "model, losses = train_model(model, X_train, y_train)\n",
    "\n",
    "# The loss should decrease with every iteration (epoch) over the training data.\n",
    "print_results(model, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Threshold.__init__() missing 2 required positional arguments: 'threshold' and 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m activation_functions \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mELU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mELU(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHardshrink\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mHardshrink(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHardsigmoin\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mHardsigmoid(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHardswish\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mHardswish(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mHardtanh\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mHardtanh(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mLeadkyReLU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mLeakyReLU(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mLogSigmoid\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mLogSigmoid(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m#'MultiheadAttention': nn.MultiheadAttention(embed_dim, num_heads),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPReLU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mPReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mReLU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mReLU6\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mReLU6(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mRReLU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mRReLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSELU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSELU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mCELU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mCELU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mGELU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mGELU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSigmoid\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSigmoid(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSiLU\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSiLU(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMish\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mMish(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSoftplus\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSoftplus(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSoftshrink\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSoftshrink(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mSoftsign\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mSoftsign(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTanh\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mTanh(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mTanhshrink\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39mTanhshrink(),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mThreshold\u001b[39m\u001b[39m'\u001b[39m: nn\u001b[39m.\u001b[39;49mThreshold(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39m#'GLU': nn.GLU(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m#'Softmin': nn.Softmin(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     \u001b[39m#'Softmax': nn.Softmax(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m#'Softmax2d': nn.Softmax2d(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39m#'LogSoftmax': nn.LogSoftmax(),\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     \u001b[39m#'AdaptiveLogSoftmaxWithLoss': nn.AdaptiveLogSoftmaxWithLoss()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/keithpij/code/python-sandbox/ml/pytorch/activation_functions/activation_functions_intro.ipynb#X62sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: Threshold.__init__() missing 2 required positional arguments: 'threshold' and 'value'"
     ]
    }
   ],
   "source": [
    "activation_functions = {\n",
    "    'ELU': nn.ELU(),\n",
    "    'Hardshrink': nn.Hardshrink(),\n",
    "    'Hardsigmoin': nn.Hardsigmoid(),\n",
    "    'Hardswish': nn.Hardswish(),\n",
    "    'Hardtanh': nn.Hardtanh(),\n",
    "    'LeadkyReLU': nn.LeakyReLU(),\n",
    "    'LogSigmoid': nn.LogSigmoid(),\n",
    "    #'MultiheadAttention': nn.MultiheadAttention(embed_dim, num_heads),\n",
    "    'PReLU': nn.PReLU(),\n",
    "    'ReLU': nn.ReLU(),\n",
    "    'ReLU6': nn.ReLU6(),\n",
    "    'RReLU': nn.RReLU(),\n",
    "    'SELU': nn.SELU(),\n",
    "    'CELU': nn.CELU(),\n",
    "    'GELU': nn.GELU(),\n",
    "    'Sigmoid': nn.Sigmoid(),\n",
    "    'SiLU': nn.SiLU(),\n",
    "    'Mish': nn.Mish(),\n",
    "    'Softplus': nn.Softplus(),\n",
    "    'Softshrink': nn.Softshrink(),\n",
    "    'Softsign': nn.Softsign(),\n",
    "    'Tanh': nn.Tanh(),\n",
    "    'Tanhshrink': nn.Tanhshrink(),\n",
    "    'Threshold': nn.Threshold(),\n",
    "    #'GLU': nn.GLU(),\n",
    "    #'Softmin': nn.Softmin(),\n",
    "    #'Softmax': nn.Softmax(),\n",
    "    #'Softmax2d': nn.Softmax2d(),\n",
    "    #'LogSoftmax': nn.LogSoftmax(),\n",
    "    #'AdaptiveLogSoftmaxWithLoss': nn.AdaptiveLogSoftmaxWithLoss()\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
