{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "Teaching a Model AND and OR<br>\n",
    "&emsp;Create Boolean Data<br>\n",
    "&emsp;Design a Model<br>\n",
    "&emsp;Train the Model<br>\n",
    "&emsp;Test the Model<br>\n",
    "Teaching a Model XOR<br>\n",
    "&emsp;Create Boolean Data<br>\n",
    "&emsp;Design a Model<br>\n",
    "&emsp;Train the Model<br>\n",
    "&emsp;Test the Model<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random as rnd\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "import utilities as util\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Boolean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Dimenstions: 2\n",
      "X_train Shape: (1000, 2)\n",
      "X_train type: float32\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 0.]]\n",
      "y_train Dimenstions: 2\n",
      "y_train Shape: (1000, 1)\n",
      "y_train type: float32\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "def create_boolean_data(size: int=1000) -> Tuple:\n",
    "    '''\n",
    "    This function will generate a training and validation set for the logical AND and OR functions.\n",
    "    In other words, each sample will contain two boolean values and the label for each sample will be \n",
    "    either (x1 and x2) or (x1 or x2).\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    count = int(size/2)\n",
    "    for _ in range(count):\n",
    "        x1 = rnd.randint(0, 1)\n",
    "        x2 = rnd.randint(0, 1)\n",
    "        label_and = x1 and x2\n",
    "        label_or = x1 or x2\n",
    "        # Append the and data.\n",
    "        sample = [x1, x2]\n",
    "        X.append(sample)\n",
    "        y.append(label_and)\n",
    "        # Append the or data.\n",
    "        X.append(sample)\n",
    "        y.append(label_or)\n",
    "\n",
    "    X, y = np.array(X, dtype=np.float32), np.array(y, np.float32)\n",
    "    X = np.reshape(X, (size, 2))\n",
    "    y = np.reshape(y, (size, 1))\n",
    "    return X, y\n",
    "\n",
    "'''\n",
    "    #self.X = np.array(X)   #torch.from_numpy(X)\n",
    "    #self.y = np.array(y)   #torch.from_numpy(y)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, shuffle=True, stratify=y, random_state=42)\n",
    "    #self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(X_remaining, y_remaining, train_size=0.5, shuffle=True, stratify=y_remaining, random_state=42)\n",
    "    X_train = np.array(X_train)\n",
    "    X_valid = np.array(X_valid)\n",
    "    y_train = np.array(y_train)\n",
    "    y_valid = np.array(y_valid)\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "'''\n",
    "\n",
    "class BooleanDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index, None], self.y[index, None]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "X_train, y_train = create_boolean_data(1000)\n",
    "print('X_train Dimenstions:', X_train.ndim)\n",
    "print('X_train Shape:', X_train.shape)\n",
    "print('X_train type:', X_train.dtype)\n",
    "print(X_train[:5])\n",
    "\n",
    "print('y_train Dimenstions:', y_train.ndim)\n",
    "print('y_train Shape:', y_train.shape)\n",
    "print('y_train type:', y_train.dtype)\n",
    "print(y_train[:5])\n",
    "\n",
    "#X_train, X_valid, y_train, y_valid = create_boolean_data(1000)\n",
    "#train_dataset = BooleanDataset(X_train, y_train)\n",
    "#valid_dataset = BooleanDataset(X_valid, y_valid)\n",
    "\n",
    "#print('X_train Dimenstions:', train_dataset.X.ndim)\n",
    "#print('X_train Shape:', train_dataset.X.shape)\n",
    "#print(train_dataset.X[:5])\n",
    "\n",
    "#print('y_train Dimenstions:', train_dataset.y.ndim)\n",
    "#print('y_train Shape:', train_dataset.y.shape)\n",
    "#print(train_dataset.y[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AndOrModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AndOrModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(2, 1, bias=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        l1 = self.linear1(input)\n",
    "        output = F.sigmoid(l1)\n",
    "        return output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Model and Print the Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[0.5406, 0.5869]])\n",
      "linear1.bias tensor([-0.1657])\n"
     ]
    }
   ],
   "source": [
    "model = AndOrModel()\n",
    "util.print_parameters(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Model and Print the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 2,\n",
    "    'epochs': 10,\n",
    "    'lr': 0.01,\n",
    "    'loss_function': nn.MSELoss()\n",
    "}\n",
    "\n",
    "def train_batches(dataloader, model, loss_fn, optimizer):\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    for X, y in dataloader:\n",
    "        # Compute prediction error\n",
    "        print('X:', X, type(X), X.dtype)\n",
    "        print('y:', y, type(y), y.dtype)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss_per_batch = total_loss / num_batches\n",
    "    return avg_loss_per_batch\n",
    "\n",
    "\n",
    "def validate_batches(dataloader, model, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            loss += loss_fn(pred, y).item()\n",
    "    avg_loss_per_batch = total_loss / num_batches\n",
    "    return avg_loss_per_batch\n",
    "\n",
    "\n",
    "def train_model(config, model, train_dataset, valid_dataset):\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_size = config['batch_size']\n",
    "    epochs = config['epochs']\n",
    "    loss_fn = config['loss_function']\n",
    "    lr = config['lr']\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    results = []\n",
    "    for epoch in range(epochs):\n",
    "        avg_loss_per_batch = train_batches(train_loader, model, loss_fn, optimizer)\n",
    "        result = {'train_loss': avg_loss_per_batch}\n",
    "        avg_loss_per_batch = validate_batches(valid_loader, model, loss_fn)\n",
    "        result = {'valid_loss': avg_loss_per_batch}\n",
    "        result['epoch'] = epoch + 1\n",
    "        result['process_id'] = os.getpid()\n",
    "        results.append(result)\n",
    "\n",
    "    duration = time.time() - start_time\n",
    "    return model, results, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 126.08957962400746\n",
      "10 : 126.08029682119377\n",
      "20 : 126.0716088162153\n",
      "30 : 126.06346865516389\n",
      "40 : 126.0558173043537\n",
      "50 : 126.04862089114613\n",
      "60 : 126.0418329979293\n",
      "70 : 126.0354242491594\n",
      "80 : 126.02935997804161\n",
      "90 : 126.02361651181127\n",
      "99 : 126.01870402850909\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fix train_model it is not working.\n",
    "#model, results, duration = train_model(config, model, train_dataset, valid_dataset)\n",
    "\n",
    "config = {\n",
    "    'epochs': 100,\n",
    "    'lr': 0.01,\n",
    "    'loss_function': nn.MSELoss()\n",
    "}\n",
    "\n",
    "model, losses = util.train_model(model, config, X_train, y_train)\n",
    "\n",
    "# The loss should decrease with every iteration (epoch) over the training data.\n",
    "util.print_results(model, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight tensor([[3.8806, 3.8805]])\n",
      "linear1.bias tensor([-3.8763])\n"
     ]
    }
   ],
   "source": [
    "util.print_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model(torch.from_numpy(X)).detach().item() for X in X_valid]\n",
    "util.plot_data(np.array(X_train), np.array(y_train), np.array(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Quadratic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quadratic_data(a:float, b: float, c:float) -> Tuple[List[float], List[float]]:\n",
    "    X = [float(x) for x in range(-10, 11)]\n",
    "    y = [a*(x**2)+(b*x)+c for x in X]\n",
    "    X, y = np.array(X, dtype=np.float32), np.array(y, np.float32)\n",
    "    X = np.reshape(X, (len(X), 1))\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = create_quadratic_data(5, 2, 3)\n",
    "\n",
    "print('X_train Dimenstions:',X_train.ndim)\n",
    "print('X_train Shape:', X_train.shape)\n",
    "print(X_train[:2])\n",
    "\n",
    "print('y_train Dimenstions:',y_train.ndim)\n",
    "print('y_train Shape:', y_train.shape)\n",
    "print(y_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegressionModel()\n",
    "model, losses = train_model(model, X_train, y_train)\n",
    "\n",
    "# The loss should decrease with every iteration (epoch) over the training data.\n",
    "print_results(model, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [model(torch.from_numpy(X)).detach().item() for X in X_train]\n",
    "plot_data(np.array(X_train), np.array(y_train), np.array(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuadraticRegressionModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(QuadraticRegressionModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(1, 6, bias=True)\n",
    "        self.linear2 = nn.Linear(6, 6, bias=True)\n",
    "        self.linear3 = nn.Linear(6, 1, bias=True)\n",
    "\n",
    "    def forward(self, x, log=False):\n",
    "        x = F.dropout(F.relu(self.linear1(x)), p=0.5)\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        #out = self.linear1(input)\n",
    "        #out = F.relu(out)\n",
    "        #out = F.dropout(out, p=0.5)\n",
    "        #out = self.linear2(out)\n",
    "        #out = F.relu(out)\n",
    "        #out = self.linear3(out)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the Untrained Model with a Single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuadraticRegressionModel()\n",
    "X = torch.tensor([1], dtype=torch.float32)\n",
    "prediction = model(X, log=True)\n",
    "print(X)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuadraticRegressionModel()\n",
    "model, losses = train_model(model, X_train, y_train)\n",
    "\n",
    "# The loss should decrease with every iteration (epoch) over the training data.\n",
    "print_results(model, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot labels and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.eval() # Tell the model we are evaluating it so that it does not learn or dropout.\n",
    "predictions = [model(torch.from_numpy(X)).detach().item() for X in X_train]\n",
    "\n",
    "plot_data(np.array(X_train), np.array(y_train), np.array(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
