{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick refresher on torch.zeros. The parameters we will be using will create vector with three elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]])\n",
      "Shape: torch.Size([1, 3])\n",
      "ndim 2\n",
      "\n",
      "\n",
      "tensor([[[0., 0., 0.]]])\n",
      "Shape: torch.Size([1, 1, 3])\n",
      "ndim 3\n"
     ]
    }
   ],
   "source": [
    "test_input = torch.zeros(1, 3)\n",
    "test_input_view = test_input.view(1, 1, -1)\n",
    "\n",
    "print(test_input)\n",
    "print('Shape:', test_input.shape)\n",
    "print('ndim', test_input.ndim)\n",
    "\n",
    "print('\\n')\n",
    "print(test_input_view)\n",
    "print('Shape:', test_input_view.shape)\n",
    "print('ndim', test_input_view.ndim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the LSTM.<br><br> Note: Pytorch has a random number generator (RNG) that changes state everytime a function or method that requires a random number is called. It turns out that the LSTM class uses random numbers. So, to get an LSTM object with the same state each time we test we will use the torch.manual_seed function. Note: this function must be called prior to every Pytorch function or method that uses random numbers if you want the same results each time. This is due to the fact that a call to the RNG changes the internal state of the RNG so that the next caller will not get the same results. That is why I chose not to use torch.randn() when creating the test inputs and inializing the hidden state. If I did I would have to call the torch.manual_seed function before every single call to torch.randn() which would be messy and is also hard to do in a comprehension which is used to create my sample inputs. You can get an object that represents the state of the random number generator by calling torch.get_rng_state()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out: tensor([[[0.1731, 0.0875, 0.0087]]], grad_fn=<StackBackward0>)\n",
      "\n",
      "\n",
      "hidden: (tensor([[[0.1731, 0.0875, 0.0087]]], grad_fn=<StackBackward0>), tensor([[[0.3653, 0.1827, 0.0237]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "# Create the LSTM. The first parameter is the input dimension, the second is the output dimension.\n",
    "torch.manual_seed(42)\n",
    "lstm = nn.LSTM(3, 3)\n",
    "\n",
    "# Create the input. Here it is a list of length 5. Each element is a\n",
    "inputs = [torch.zeros(1, 3) for _ in range(5)]\n",
    "\n",
    "# Initialize the hidden state which is a tuple of tensors.\n",
    "hidden = (torch.zeros(1, 1, 3),\n",
    "          torch.zeros(1, 1, 3))\n",
    "\n",
    "# Loop through the inputs.\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "print('out:', out)\n",
    "print('\\n')\n",
    "print('hidden:', hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "\n",
    "print('out:', out)\n",
    "print('\\n')\n",
    "print('hidden:', hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part of Speech Tagging Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "EPOCHS = 100\n",
    "HIDDEN_DIM = 6\n",
    "LR = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n",
      "{'Determiner': 0, 'Noun': 1, 'Verb': 2}\n",
      "['Determiner', 'Noun', 'Verb']\n"
     ]
    }
   ],
   "source": [
    "training_data = [\n",
    "    (\"The dog ate the apple\".split(), ['Determiner', 'Noun', 'Verb', 'Determiner', 'Noun']),\n",
    "    (\"Everybody read that book\".split(), ['Noun', 'Verb', 'Determiner', 'Noun'])\n",
    "]\n",
    "\n",
    "word_to_ix = {}\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
    "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
    "\n",
    "tag_to_ix = {'Determiner': 0, 'Noun': 1, 'Verb': 2}  # Assign each tag with a unique index\n",
    "ix_to_tag = ['Determiner', 'Noun', 'Verb']  # Assign each tag with a unique index\n",
    "\n",
    "\n",
    "def prepare_sequence(seq: list, word_to_ix: dict) -> torch.Tensor:\n",
    "    idxs = [word_to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.int64)\n",
    "\n",
    "\n",
    "def translate_predictions(tag_scores):\n",
    "    predicted_indecies = torch.argmax(tag_scores, dim=1)\n",
    "    predictions = [ix_to_tag[i] for i in predicted_indecies.numpy()]\n",
    "    return predictions\n",
    "    \n",
    "\n",
    "print(word_to_ix)\n",
    "print(tag_to_ix)\n",
    "print(ix_to_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Model, Loss Function, and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions Before Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'ate', 'the', 'apple']\n",
      "['The', 'dog', 'ate', 'the', 'apple']\n",
      "['Determiner', 'Noun', 'Verb', 'Determiner', 'Noun']\n",
      "tensor([[-0.0259, -4.5027, -4.2358],\n",
      "        [-4.5316, -0.0617, -3.0154],\n",
      "        [-2.6551, -2.9622, -0.1301],\n",
      "        [-0.1583, -3.9917, -2.0562],\n",
      "        [-4.2915, -0.0241, -4.5954]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_prediction(sentence: list) -> None:\n",
    "    with torch.no_grad():\n",
    "        inputs = prepare_sequence(sentence, word_to_ix)\n",
    "        tag_scores = model(inputs)\n",
    "        predictions = translate_predictions(tag_scores)\n",
    "        print(sentence)\n",
    "        print(predictions)\n",
    "        print(tag_scores)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "print_prediction(training_data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'ate', 'the', 'apple']\n",
      "['Determiner', 'Noun', 'Verb', 'Determiner', 'Noun']\n",
      "tensor([[-0.0259, -4.5027, -4.2358],\n",
      "        [-4.5316, -0.0617, -3.0154],\n",
      "        [-2.6551, -2.9622, -0.1301],\n",
      "        [-0.1583, -3.9917, -2.0562],\n",
      "        [-4.2915, -0.0241, -4.5954]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    predictions = translate_predictions(tag_scores)\n",
    "    print(training_data[0][0])\n",
    "    print(predictions)\n",
    "    print(tag_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.0 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
