{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xbbncc8/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import preprocessor as pre\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "config = {\n",
    "    'smoke_test_size': 500,  # Length of training set. 0 for all reviews.\n",
    "    'epochs': 10,             # Total number of epochs\n",
    "    'batch_size': 100,        # Batch size for each epoch\n",
    "    'sequence_len': 200,     # Number of tokens (words) to put into each review.\n",
    "    'vocab_size': 7000,      # Vocabulary size\n",
    "    'output_size': 1,\n",
    "    'embedding_dim': 400,\n",
    "    'hidden_dim': 256,\n",
    "    'n_layers': 2,\n",
    "    'dropout_prob': 0.5,\n",
    "    'lr': 0.001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device('cuda')\n",
    "    print('GPU is available.')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('GPU not available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(os.getcwd(), 'aclImdb', 'IMDB Dataset.csv')\n",
    "df = pd.read_csv(data_file)\n",
    "df.head()\n",
    "\n",
    "X, y = df['review'].values, df['sentiment'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.5, stratify=y)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=.8, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = pre.preprocess_train_valid_data(config)\n",
    "X_test, y_test = pre.get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train data is (20000, 200)\n",
      "shape of train data is (5000, 200)\n",
      "shape of test data is (25000, 200)\n"
     ]
    }
   ],
   "source": [
    "print(f'shape of train data is {X_train.shape}')\n",
    "print(f'shape of train data is {X_valid.shape}')\n",
    "print(f'shape of test data is {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = pd.Series(y_train).value_counts()\n",
    "sns.barplot(x=np.array(['negative','positive']), y=dd.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_string(s):\n",
    "    # Remove all non-word characters (everything except numbers and letters)\n",
    "    s = re.sub(r'[^\\w\\s]', '', s)\n",
    "    # Replace all runs of whitespaces with no space\n",
    "    s = re.sub(r'\\s+', '', s)\n",
    "    # replace digits with no space\n",
    "    s = re.sub(r'\\d', '', s)\n",
    "\n",
    "    return s\n",
    "\n",
    "def pad(X, sequence_len):\n",
    "    features = np.zeros((len(X), sequence_len),dtype=int)\n",
    "    for ii, review in enumerate(X):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:sequence_len]\n",
    "    return features\n",
    "\n",
    "def create_tokens(X_train, config):\n",
    "    vocab_size = config['vocab_size']\n",
    "    word_list = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "\n",
    "    for entry in X_train:\n",
    "        for word in entry.lower().split():\n",
    "            word = preprocess_string(word)\n",
    "            if word not in stop_words and word != '':\n",
    "                word_list.append(word)\n",
    "\n",
    "    count_by_word = Counter(word_list)\n",
    "    # sorting on the basis of most common words\n",
    "    count_by_word_sorted = sorted(count_by_word, key=count_by_word.get, reverse=True)[:vocab_size-1]\n",
    "    # creating a dict\n",
    "    word_to_int_mapping = {w:i+1 for i,w in enumerate(count_by_word_sorted)}\n",
    "    return word_to_int_mapping\n",
    "\n",
    "def tokenize(X, y, mapping, config):\n",
    "    sequence_len = config['sequence_len']\n",
    "    new_X = []\n",
    "    for entry in X:\n",
    "        new_X.append([mapping[preprocess_string(word)] for word in entry.lower().split() \n",
    "                                    if preprocess_string(word) in mapping.keys()])\n",
    "            \n",
    "    new_X = pad(new_X, sequence_len)\n",
    "    new_y = [1 if label =='positive' else 0 for label in y]  \n",
    "    \n",
    "    return np.array(new_X), np.array(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_int_mapping = create_tokens(X_train, config)\n",
    "X_train, y_train = tokenize(X_train, y_train, word_to_int_mapping, config)\n",
    "X_valid, y_valid = tokenize(X_valid, y_valid, word_to_int_mapping, config)\n",
    "X_test, y_test = tokenize(X_test, y_test, word_to_int_mapping, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentLSTM(nn.Module):\n",
    "    '''\n",
    "    An LSTM is a type of RNN network that can be used to perform Sentiment analysis.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, vocab_size, output_dim, embedding_dim, hidden_dim, n_layers, batch_size, dropout_prob):\n",
    "        '''\n",
    "        Initialize the model and set up the layers.\n",
    "        '''\n",
    "        super(SentimentLSTM, self).__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.dropout_prob = dropout_prob\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # LSTM Layer\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
    "\n",
    "        #self.hidden = self.init_hidden()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Linear layer\n",
    "        self.fcl = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        # Sigmoid layer\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        '''\n",
    "        Forward pass\n",
    "        '''\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # embeddings and lstm_out\n",
    "        embeds = self.embedding(x)\n",
    "        \n",
    "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
    "\n",
    "        # stack up lstm outputs\n",
    "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
    "\n",
    "        # fully-connected layer\n",
    "        out = self.dropout(lstm_out)\n",
    "        out = self.fcl(out)\n",
    "\n",
    "        # sigmoid function\n",
    "        sig_out = self.sig(out)\n",
    "\n",
    "        # reshape to be batch_size first\n",
    "        sig_out = sig_out.view(batch_size, -1)\n",
    "        sig_out = sig_out[:, -1] # get last batch of labels\n",
    "\n",
    "        # return last sigmoid output and hidden state\n",
    "        return sig_out, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=None):\n",
    "        ''' \n",
    "        Initializes hidden state\n",
    "        Creates two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
    "        initialized to zero, for hidden state and cell state of LSTM.\n",
    "\n",
    "        Note: The batch_size needs to be 1 for predictions.\n",
    "        '''\n",
    "        if not batch_size:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        h0 = torch.zeros((self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
    "        c0 = torch.zeros((self.n_layers, batch_size, self.hidden_dim)).to(device)\n",
    "        hidden = (h0,c0)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = config['n_layers']\n",
    "vocab_size = config['vocab_size']\n",
    "embedding_dim = config['embedding_dim']\n",
    "output_dim = config['output_dim']\n",
    "hidden_dim = config['hidden_dim']\n",
    "dropout_prob = config['dropout_prob']\n",
    "\n",
    "model = SentimentLSTM(vocab_size, output_dim, embedding_dim, hidden_dim, n_layers, batch_size, dropout_prob)\n",
    "\n",
    "#moving to gpu\n",
    "model.to(device)\n",
    "\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc919a8c9f3b0b92e1d085faab71fe86a296093fb313f99140bffe2c1d0fe07d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
