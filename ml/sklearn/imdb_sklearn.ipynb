{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from os import system, listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#system('wget \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"')\n",
    "#system('tar -xzf \"aclImdb_v1.tar.gz\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "repo_root = cwd.parent.parent\n",
    "aclimdb_folder = os.path.join(repo_root, 'datasets', 'aclImdb')\n",
    "\n",
    "TRAIN_NEGATIVE_REVIEWS_DIR = os.path.join(aclimdb_folder, 'train', 'neg')\n",
    "TRAIN_POSITIVE_REVIEWS_DIR = os.path.join(aclimdb_folder, 'train', 'pos')\n",
    "TEST_NEGATIVE_REVIEWS_DIR = os.path.join(aclimdb_folder, 'test', 'neg')\n",
    "TEST_POSITIVE_REVIEWS_DIR = os.path.join(aclimdb_folder, 'test', 'pos')\n",
    "\n",
    "\n",
    "def get_train_data(smoke_test_size=0):\n",
    "    '''\n",
    "    Load all the raw negative and positive data from the review files.\n",
    "    If data is needed for a quick experiment (smoke test) then we want to get an equal amount of files\n",
    "    from the negative dir and the positive dir.\n",
    "    '''\n",
    "    max_files = 0\n",
    "    if smoke_test_size:\n",
    "        max_files = smoke_test_size/2\n",
    "\n",
    "    X_negative, y_negative = read_files(TRAIN_NEGATIVE_REVIEWS_DIR, 0, max_files)\n",
    "    X_positive, y_positive = read_files(TRAIN_POSITIVE_REVIEWS_DIR, 1, max_files)\n",
    "    X = X_negative + X_positive\n",
    "    y = y_negative + y_positive\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def get_test_data():\n",
    "    '''\n",
    "    Load all the raw negative and positive test data from the review files.\n",
    "    '''\n",
    "    X_negative, y_negative = read_files(TEST_NEGATIVE_REVIEWS_DIR, 0)\n",
    "    X_positive, y_positive = read_files(TEST_POSITIVE_REVIEWS_DIR, 1)\n",
    "    X_test = X_negative + X_positive\n",
    "    y_test = y_negative + y_positive\n",
    "\n",
    "    return X_test, y_test\n",
    "\n",
    "\n",
    "def read_files(directory, label, max_files=0) -> tuple:\n",
    "    '''\n",
    "    Retrieve the Imdb data from the specified folder.\n",
    "    '''\n",
    "    count = 0\n",
    "    X = []\n",
    "    y = []\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        with open(file_path, 'r') as f:\n",
    "            review = f.read()\n",
    "        clean = clean_entry(review)\n",
    "        X.append(clean)\n",
    "        y.append(label)\n",
    "        count += 1\n",
    "        if max_files and count >= max_files:\n",
    "            break\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def clean_entry(review):\n",
    "    remove_breaks = review.replace('<br />', ' ')\n",
    "    lower = remove_breaks.lower()\n",
    "    #for c in punctuation:\n",
    "    #    lower = lower.replace(c, ' ')\n",
    "    valid_characters = [c for c in lower if c not in punctuation]\n",
    "    cleaned = ''.join(valid_characters)\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 25000\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_data()\n",
    "\n",
    "print('Length of training set:', len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_frame(folder: str) -> pd.DataFrame:\n",
    "    '''\n",
    "    folder - the root folder of train or test dataset\n",
    "    Returns: a DataFrame with the combined data from the input folder\n",
    "    '''\n",
    "    pos_folder = f'{folder}/pos' # positive reviews\n",
    "    neg_folder = f'{folder}/neg' # negative reviews\n",
    "    \n",
    "    def get_files(fld: str) -> list:\n",
    "        '''\n",
    "        fld - positive or negative reviews folder\n",
    "        Returns: a list with all files in input folder\n",
    "        '''\n",
    "        return [join(fld, f) for f in listdir(fld) if isfile(join(fld, f))]\n",
    "    \n",
    "    def append_files_data(data_list: list, files: list, label: int) -> None:\n",
    "        '''\n",
    "        Appends to 'data_list' tuples of form (file content, label)\n",
    "        for each file in 'files' input list\n",
    "        '''\n",
    "        for file_path in files:\n",
    "            with open(file_path, 'r') as f:\n",
    "                text = f.read()\n",
    "                data_list.append((text, label))\n",
    "    \n",
    "    pos_files = get_files(pos_folder)\n",
    "    neg_files = get_files(neg_folder)\n",
    "    \n",
    "    data_list = []\n",
    "    append_files_data(data_list, pos_files, 1)\n",
    "    append_files_data(data_list, neg_files, 0)\n",
    "    shuffle(data_list)\n",
    "    \n",
    "    text, label = tuple(zip(*data_list))\n",
    "    # replacing line breaks with spaces\n",
    "    text = list(map(lambda txt: re.sub('(<br\\s*/?>)+', ' ', txt), text))\n",
    "    \n",
    "    return pd.DataFrame({'text': text, 'label': label})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cwd = Path(os.getcwd())\n",
    "repo_root = cwd.parent.parent\n",
    "train_folder = os.path.join(repo_root, 'aclImdb', 'train')\n",
    "test_folder = os.path.join(repo_root, 'aclImdb', 'test')\n",
    "\n",
    "imdb_train = create_data_frame('aclImdb/train')\n",
    "imdb_test = create_data_frame('aclImdb/test')\n",
    "\n",
    "#system(\"mkdir 'csv'\")\n",
    "imdb_train.to_csv('csv/imdb_train.csv', index=False)\n",
    "imdb_test.to_csv('csv/imdb_test.csv', index=False)\n",
    "\n",
    "# imdb_train = pd.read_csv('csv/imdb_train.csv')\n",
    "# imdb_test = pd.read_csv('csv/imdb_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large datasets consider using the following imports to save the preprocessed data.<br>\n",
    "\n",
    "from joblib import dump, load               # These functions can be used for saving and loading sklearn objects.<br>\n",
    "from scipy.sparse import save_npz, load_npz # Functions for saving and loading sparse matrices.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "def create_unigram_counts(X):\n",
    "    '''\n",
    "    Create unigram counts from an array of reviews.\n",
    "    '''\n",
    "    unigram_vectorizer = CountVectorizer(ngram_range=(1, 1))\n",
    "    unigram_vectorizer.fit(X)\n",
    "    return unigram_vectorizer.transform(X)\n",
    "\n",
    "\n",
    "def create_unigram_tf_idf_counts(X_unigram):\n",
    "    '''\n",
    "    Creates unigram Tf-Idf counts from an array of reviews.\n",
    "    '''\n",
    "    unigram_tf_idf_transformer = TfidfTransformer()\n",
    "    unigram_tf_idf_transformer.fit(X_unigram)\n",
    "    return unigram_tf_idf_transformer.transform(X_unigram)\n",
    "\n",
    "\n",
    "def create_bigram_counts(X):\n",
    "    '''\n",
    "    Create bigram counts from an array of reviews.\n",
    "    '''\n",
    "    bigram_vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
    "    bigram_vectorizer.fit(X)\n",
    "    return bigram_vectorizer.transform(X)\n",
    "\n",
    "\n",
    "def create_bigram_tf_idf_counts(X_bigram):\n",
    "    '''\n",
    "    Creates bigram Tf-Idf counts from an array of reviews.\n",
    "    '''\n",
    "    bigram_tf_idf_transformer = TfidfTransformer()\n",
    "    bigram_tf_idf_transformer.fit(X_bigram)\n",
    "\n",
    "    return bigram_tf_idf_transformer.transform(X_train_bigram)\n",
    "\n",
    "\n",
    "X_train_unigram = create_unigram_counts(X_train)\n",
    "X_train_unigram_tf_idf = create_unigram_tf_idf_counts(X_train_unigram)\n",
    "X_train_bigram = create_bigram_counts(X_train)\n",
    "X_train_bigram_tf_idf = create_bigram_tf_idf_counts(X_train_bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SGDClassifier' from 'sklearnex.linear_model' (/Users/xbbncc8/Documents/code/python-sandbox/.venv/lib/python3.7/site-packages/sklearnex/linear_model/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jh/zsmd687d42g1w4syrs1djhsm0000gp/T/ipykernel_89611/2744037336.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from sklearn.linear_model import SGDClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearnex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsr_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SGDClassifier' from 'sklearnex.linear_model' (/Users/xbbncc8/Documents/code/python-sandbox/.venv/lib/python3.7/site-packages/sklearnex/linear_model/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "def train_and_show_scores(X: csr_matrix, y: np.array, title: str) -> None:\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, shuffle=True, stratify=y, random_state=42)\n",
    "\n",
    "    clf = SGDClassifier()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_score = clf.score(X_train, y_train)\n",
    "    valid_score = clf.score(X_valid, y_valid)\n",
    "    print(f'{title}\\nTrain score: {round(train_score, 2)} ; Validation score: {round(valid_score, 2)}\\n')\n",
    "\n",
    "\n",
    "train_and_show_scores(X_train_unigram, y_train, 'Unigram Counts')\n",
    "train_and_show_scores(X_train_unigram_tf_idf, y_train, 'Unigram Tf-Idf')\n",
    "train_and_show_scores(X_train_bigram, y_train, 'Bigram Counts')\n",
    "train_and_show_scores(X_train_bigram_tf_idf, y_train, 'Bigram Tf-Idf')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc919a8c9f3b0b92e1d085faab71fe86a296093fb313f99140bffe2c1d0fe07d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb30887f202a295f03f14bdc6c33a4c2546440b9bc6792bc5945ccf510842fff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
